{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport sklearn\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.naive_bayes import MultinomialNB\\n\\n\\nimport matplotlib.pyplot as plt\\nimport matplotlib.dates as mdates\\nimport matplotlib.ticker as mtick\\n\\nfrom scipy.interpolate import interp1d\\n\\n%matplotlib inline\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "'''\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "%matplotlib inline\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dateYear(date):\n",
    "    return \n",
    "\n",
    "def dateConverter(date):\n",
    "    \n",
    "    monthUKFR = dict()\n",
    "    monthUKFR['janvier'] = 1\n",
    "    monthUKFR['février'] = 2\n",
    "    monthUKFR['mars'] = 3\n",
    "    monthUKFR['avril'] = 4\n",
    "    monthUKFR['mai'] = 5\n",
    "    monthUKFR['juin'] = 6\n",
    "    monthUKFR['juillet'] = 7\n",
    "    monthUKFR['août'] = 8\n",
    "    monthUKFR['septembre'] = 9\n",
    "    monthUKFR['octobre'] = 10\n",
    "    monthUKFR['novembre'] = 11\n",
    "    monthUKFR['décembre'] = 12\n",
    "    \n",
    "    day = int(re.findall(r'\\S+', date)[0])\n",
    "    month = monthUKFR[re.findall(r'\\S+', date)[1]]\n",
    "    year = int(re.findall(r'\\S+', date)[2])\n",
    "    \n",
    "    return datetime(year,month,day)\n",
    "\n",
    "\n",
    "\n",
    "reviews=pd.read_csv('reviews.csv', encoding = 'utf-8')\n",
    "reviews['reviewYear'] = reviews.reviewDate.apply(lambda x: dateConverter(x))\n",
    "#reviews_fr = reviews[reviews['language'] == 'fr']\n",
    "reviews_en = reviews[reviews['language'] == 'en']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class barometre:\n",
    "    \n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "        self.categories = dict()\n",
    "    \n",
    "    def addCategory(self, name, words):\n",
    "        #ajoute une nouvelle catégorie au baromètre. Les catégories sont définies par un groupe de mots.\n",
    "        self.categories[name] = words\n",
    "    \n",
    "    def vectorizeReviews(self):\n",
    "        self.vect = CountVectorizer(lowercase=True, preprocessor=None, token_pattern=r'\\b\\w+\\b', ngram_range=(1, 2), max_df=.8, min_df=1)\n",
    "        self.vectM = self.vect.fit_transform(self.reviews.reviewDescription)\n",
    "        \n",
    "    def tagCat(self,catName):\n",
    "        for w in self.categories[catName]:\n",
    "            vocab = self.vect.vocabulary_.get(w) #la colonne du mot de la catégorie\n",
    "            slice = self.vectM[:,vocab].toarray() #l'ensemble des reviews contenant ce mot\n",
    "            if catName in baro.reviews.columns:\n",
    "                baro.reviews[catName] =(baro.reviews[catName].values | (slice > 0)) #création d'une colonne du nom de la catégorie\n",
    "            else:\n",
    "                baro.reviews[catName] = (slice > 0) #création d'une colonne du nom de la catégorie\n",
    "            \n",
    "    def plotCat(self):\n",
    "        d = self.reviews.loc[:,self.categories.keys()] #reviews filtrées sur les catégories\n",
    "        d = d[d.sum(axis=1) > 0] #reviews qui ont été taggés au moins une fois\n",
    "        df = pd.concat([d, self.reviews.reviewYear.apply(lambda x: (x.year, x.month))], axis=1, join_axes=[d.index] ) #ajout de l'année\n",
    "        valeurs = (df.groupby('reviewYear').sum()/\n",
    "                   self.reviews.groupby(self.reviews.reviewYear.apply(lambda x: (x.year, x.month))).count()).loc[:,self.categories.keys()] #décompte du nombre par an\n",
    "        \n",
    "        valeurs = valeurs.dropna()\n",
    "        \n",
    "        x = valeurs.index.values\n",
    "        \n",
    "        y1 = valeurs.iloc[:,0].astype('float')\n",
    "        y2 = valeurs.iloc[:,1]\n",
    "        \n",
    "        xd = [datetime(t[0],t[1],1) for t in x]\n",
    "    \n",
    "        plt.style.use('ggplot')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        ax.stackplot(xd, y1*100, y2*100)\n",
    "\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "        ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "\n",
    "        fmt = '%.1f%%' # Format you want the ticks, e.g. '40%'\n",
    "        yticks = mtick.FormatStrFormatter(fmt)\n",
    "        ax.yaxis.set_major_formatter(yticks)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles, labels)\n",
    "        \n",
    "    def printWord(self, word):\n",
    "        vocab = self.vect.vocabulary_.get(word) #la colonne du mot de la catégorie\n",
    "        slice = self.vectM[:,vocab].toarray() #l'ensemble des reviews contenant ce mot\n",
    "        print(self.reviews[slice > 1]['reviewDescription'])\n",
    "\n",
    "    def info(self):\n",
    "        return self.reviews.groupby(list(self.categories.keys())).reviewDescription.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "culture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindset\n"
     ]
    }
   ],
   "source": [
    " for w in baro.categories['culture']:\n",
    "    print(w)\n",
    "    vocab = baro.vect.vocabulary_.get(w) #la colonne du mot de la catégorie\n",
    "    slice = baro.vectM[:,vocab].toarray() #l'ensemble des reviews contenant ce mot\n",
    "    if 'culture' in baro.reviews.columns:\n",
    "        baro.reviews['culture'] =(baro.reviews['culture'].values | (slice > 0)) #création d'une colonne du nom de la catégorie\n",
    "    else:\n",
    "        baro.reviews['culture'] = (slice > 0) #création d'une colonne du nom de la catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pay    culture  workplace\n",
       "False  False    False        11088\n",
       "                True          1697\n",
       "       True     False            8\n",
       "                True             2\n",
       "True   False    False          272\n",
       "                True            41\n",
       "Name: reviewDescription, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pay    culture  workplace\n",
       "False  False    False        11088\n",
       "                True          1697\n",
       "       True     False            8\n",
       "                True             2\n",
       "True   False    False          272\n",
       "                True            41\n",
       "Name: reviewDescription, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baro = barometre(reviews_en)\n",
    "baro.addCategory('culture',['culture', 'mindset'])\n",
    "baro.vectorizeReviews()\n",
    "baro.addCategory('workplace',['work environment', 'workplace','environment'])\n",
    "baro.addCategory('pay',['pay', 'remuneration','wage','compensation','salary'])\n",
    "\n",
    "baro.tagCat('workplace')\n",
    "baro.tagCat('culture')\n",
    "baro.tagCat('pay')\n",
    "#baro.plotCat()\n",
    "baro.info()\n",
    "#baro.printWord('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17       Analysis and writing of macroscopic impact stu...\n",
       "122      BONNE AMBIANCE DE TRAVAIL MAIS ORGANISATION ET...\n",
       "178      My internship at BNP Paribas Securities Servic...\n",
       "179      Business and production focus,people are pleas...\n",
       "181      I have spent a very good internship with the c...\n",
       "182      Clear job assignment and possible paths of pro...\n",
       "183      Learned to developed usefull tools for co-work...\n",
       "184      Working in BPSS, in the IRP service is my firs...\n",
       "185      Analysing of financial indicators and sending ...\n",
       "186      Especially in charge of producting all final c...\n",
       "187      My job is interesting because I am always busy...\n",
       "188      Checking emails for any issues with customers ...\n",
       "189      The job at BNP was very pleasant and very inte...\n",
       "190      I believed this internship was a life time exp...\n",
       "191      I'am an open minded person ; this quality is i...\n",
       "192      This is a great Bank that offers many opportun...\n",
       "193      During this internship, my job has been divide...\n",
       "195      I did an internship at BNP Paribas Paris. It w...\n",
       "196      Before the merger with BNP, Paribas was a very...\n",
       "197      Greeting clients and making appointments,Infor...\n",
       "198      Risk analysts at the Scoring Centre handle sev...\n",
       "200      My job at BNP Paribas was enjoyable; welcoming...\n",
       "201      An amazing team and atmosphere.,I have learned...\n",
       "202      • Actively participated in all aspects of IT a...\n",
       "203      My first really job as I graduated. I learned ...\n",
       "204      Sales Trader on European markets for instituti...\n",
       "205      a typical day at work,what you learned,managem...\n",
       "206      Used to be a small company. Now as part ofBNP,...\n",
       "207      I worked directly for the head of the chemical...\n",
       "208      System engineering,To be professional every si...\n",
       "                               ...                        \n",
       "17104    A typical day at work was exactly that, it was...\n",
       "17105    Typical day starts with the first meal of the ...\n",
       "17106    Didn't like this place. Everyone who worked he...\n",
       "17107    Google is a very enriching place to work at. M...\n",
       "17108    A highly motivated and results and detailed - ...\n",
       "17109    As a Data Evaluator, i analyzed data for a pro...\n",
       "17110    Managed the production floor and report daily ...\n",
       "17111    Google is an amazing place to work and its not...\n",
       "17112    such an area to prefer, where one can get what...\n",
       "17113    Google is a great place to work, interesting w...\n",
       "17114    A good company to work for. They look after th...\n",
       "17115    I was a employee of Milestone Technologies ass...\n",
       "17116    This has to be one of the best places on earth...\n",
       "17117    Adecco is an overly complicated bureaucracy th...\n",
       "17118    Amazing experience to help Google build out th...\n",
       "17119    Great company, great training, great facilitie...\n",
       "17120    I have been working for Google 4,5 years at th...\n",
       "17121    Google had to be one of the most positive expe...\n",
       "17122    had too much fun working as a summer intern. H...\n",
       "17124    For engineers, Google is a company unlike any ...\n",
       "17125    The company is not as intimidating as some exp...\n",
       "17126    I worked in the Google HR team so I can really...\n",
       "17127    I loved my time at Google. I started as an eng...\n",
       "17146    Provide trainning with diversification.,I lear...\n",
       "17153    I loved working here. The colleagues and the c...\n",
       "17155    GEOLOCALIZAR TODOS LOS NEGOCIOS DE DURANGO ASI...\n",
       "17162    such a nice company with an amazing corporate ...\n",
       "17168    CONDUCIR LA UNIDAD DESDE LA MAÑANA HASTA LA TA...\n",
       "17175    ES UNA EMPRESA DONDE TOMAN EN CUENTA TU PALABR...\n",
       "17181    Cool benefits, but big company problems. Seems...\n",
       "Name: reviewDescription, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baro.reviews[baro.reviews[list(baro.categories.keys())].apply(lambda x: x.max(), axis=1) == 0]['reviewDescription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep = int(baro.reviews.shape[0]*0.5)\n",
    "\n",
    "xtrain = baro.reviews.reviewDescription[:sep]\n",
    "xtest = baro.reviews.reviewDescription[sep:]\n",
    "\n",
    "ytrain = baro.reviews[list(baro.categories.keys())[1]][:sep] #reviews filtrées sur les catégories\n",
    "ytest  = baro.reviews[list(baro.categories.keys())[1]][sep:]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(lowercase=True,min_df=2, max_df=.8)),\n",
    "                     ('TFIDF', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(alpha=0))])\n",
    "text_clf = text_clf.fit(xtrain, ytrain)\n",
    "\n",
    "predicted = text_clf.predict(xtest)\n",
    "print(metrics.classification_report(ytest, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xvect[:,vect.vocabulary_.get('mindset')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.max_seq_items = 2000\n",
    "pd.set_option('max_colwidth',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
